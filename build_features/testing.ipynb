{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793e2428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count         min         max\n",
      "split                                \n",
      "test    24576  1762459200  1857168000\n",
      "train  114682  1309897260  1760540400\n",
      "val     24574  1760540400  1762459200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path(r\"C:\\Users\\nimro\\PolyQuant-features\\data\")\n",
    "splits = pd.read_parquet(base / \"market_splits.parquet\")\n",
    "\n",
    "assert splits[\"market_id\"].is_unique\n",
    "assert set(splits[\"split\"].unique()) == {\"train\", \"val\", \"test\"}\n",
    "\n",
    "g = splits.groupby(\"split\")[\"end_ts\"].agg([\"count\", \"min\", \"max\"])\n",
    "print(g)\n",
    "\n",
    "# time-respecting boundaries (ties allowed)\n",
    "assert g.loc[\"train\", \"max\"] <= g.loc[\"val\", \"min\"]\n",
    "assert g.loc[\"val\", \"max\"] <= g.loc[\"test\", \"min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30181ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: sampled train\n",
      "OK: sampled val\n",
      "OK: sampled test\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "m2s = dict(zip(splits[\"market_id\"].astype(str), splits[\"split\"]))\n",
    "\n",
    "def sample_check_folder(folder, expected_split, n_files=5, n_rowgroups=3):\n",
    "    paths = list(folder.glob(\"*.parquet\"))\n",
    "    if not paths:\n",
    "        raise RuntimeError(f\"No parquet files in {folder}\")\n",
    "    for p in random.sample(paths, k=min(n_files, len(paths))):\n",
    "        pf = pq.ParquetFile(str(p))\n",
    "        rgs = list(range(pf.num_row_groups))\n",
    "        for rg in random.sample(rgs, k=min(n_rowgroups, len(rgs))):\n",
    "            t = pf.read_row_group(rg, columns=[\"market_id\"])\n",
    "            mids = t.column(0).to_pandas().astype(str).unique()\n",
    "            bad = [m for m in mids if m2s.get(m) != expected_split]\n",
    "            if bad:\n",
    "                raise RuntimeError(f\"Found wrong markets in {expected_split}: file={p.name}, examples={bad[:10]}\")\n",
    "    print(f\"OK: sampled {expected_split}\")\n",
    "\n",
    "base = Path(r\"C:\\Users\\nimro\\PolyQuant-features\\data\")\n",
    "sample_check_folder(base/\"train\", \"train\")\n",
    "sample_check_folder(base/\"val\", \"val\")\n",
    "sample_check_folder(base/\"test\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c39e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlaps: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "def collect_seen_markets(folder: Path):\n",
    "    seen = set()\n",
    "    for p in folder.glob(\"*.parquet\"):\n",
    "        pf = pq.ParquetFile(str(p))\n",
    "        for rg in range(pf.num_row_groups):\n",
    "            t = pf.read_row_group(rg, columns=[\"market_id\"])\n",
    "            mids = t.column(0).to_pandas().astype(str).unique()\n",
    "            seen.update(mids)\n",
    "    return seen\n",
    "\n",
    "base = Path(r\"C:\\Users\\nimro\\PolyQuant-features\\data\")\n",
    "seen_train = collect_seen_markets(base/\"train\")\n",
    "seen_val   = collect_seen_markets(base/\"val\")\n",
    "seen_test  = collect_seen_markets(base/\"test\")\n",
    "\n",
    "print(\"overlaps:\",\n",
    "      len(seen_train & seen_val),\n",
    "      len(seen_train & seen_test),\n",
    "      len(seen_val & seen_test))\n",
    "\n",
    "assert len(seen_train & seen_val) == 0\n",
    "assert len(seen_train & seen_test) == 0\n",
    "assert len(seen_val & seen_test) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b018b8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "expected = set(splits[\"market_id\"].astype(str))\n",
    "\n",
    "foreign_train = seen_train - expected\n",
    "foreign_val   = seen_val - expected\n",
    "foreign_test  = seen_test - expected\n",
    "\n",
    "print(len(foreign_train), len(foreign_val), len(foreign_test))\n",
    "assert len(foreign_train) == 0 and len(foreign_val) == 0 and len(foreign_test) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1322933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163832"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\nimro\\PolyQuant-features\")\n",
    "DB_PATH = BASE / \"sql\" / \"polymarket.db\"\n",
    "DATA_DIR = BASE / \"data\"  # uses your split output folders\n",
    "\n",
    "def iso_z_to_epoch(s: str) -> int:\n",
    "    dt = datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=timezone.utc)\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "def load_market_end_ts(db_path: Path) -> dict:\n",
    "    con = sqlite3.connect(str(db_path))\n",
    "    try:\n",
    "        df = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT condition_id AS market_id, end_date\n",
    "            FROM markets\n",
    "            WHERE end_date IS NOT NULL\n",
    "            \"\"\",\n",
    "            con,\n",
    "        )\n",
    "    finally:\n",
    "        con.close()\n",
    "    df[\"market_id\"] = df[\"market_id\"].astype(str)\n",
    "    df[\"end_ts\"] = df[\"end_date\"].map(iso_z_to_epoch)\n",
    "    return dict(zip(df[\"market_id\"], df[\"end_ts\"]))\n",
    "\n",
    "market_end_ts = load_market_end_ts(DB_PATH)\n",
    "len(market_end_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51474140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample file: part-000020.parquet\n",
      "picked user_id: 0xfb1c3c1ab4fb2d0cbcbb9538c8d4d357dd95963e\n",
      "rows for user in train: 511729\n",
      "\n",
      "Example: two consecutive trades (time-ordered for this user) where user_historical_pnl_before changes\n",
      "\n",
      "Trade A\n",
      "  trade_uid: e178f1fcb157648953654e8c4cb4660ff59b196a\n",
      "  ts: 2024-12-07 04:38:55 UTC\n",
      "  market_id: 0xbb79169bc66adb4fa273611251e410bb2b06fc7a1168f752762a24c5c6b36bc3\n",
      "  market_end: 2024-12-14 18:00:00 UTC\n",
      "  price: 0.14 edge: -0.14\n",
      "  user_historical_pnl_before: 0.0\n",
      "\n",
      "Trade B\n",
      "  trade_uid: 7fc35d42c579cc88294734316bd9b9ed133f4ea4\n",
      "  ts: 2024-12-09 10:39:56 UTC\n",
      "  market_id: 0x5f25affd5084282827c386dfe3fde5d9f7c51c1fa2d161642aefaf78990de951\n",
      "  market_end: 2024-12-17 00:30:00 UTC\n",
      "  price: 0.31 edge: -0.31\n",
      "  user_historical_pnl_before: 10.659995085388754\n",
      "\n",
      "Delta user_historical_pnl_before: 10.659995085388754\n",
      "\n",
      "Markets (that this user traded in train) with end_ts in (TradeA.ts, TradeB.ts]: 23\n",
      "  0xf6d46620924630920aad970d6790896ed7ba5a88c16e60b3e018ee4ead493b0f 2024-12-08 00:00:00 UTC\n",
      "  0xff2000f762a3c268f1679abc557caa9ca59451b5264c421cebdcb205a4e72d26 2024-12-08 02:30:00 UTC\n",
      "  0xfe5541745b12c896c8fefb0ef3e1b945d9d20d44aa188d9c1a4be1415a47842c 2024-12-08 18:00:00 UTC\n",
      "  0xa1545abe49521bf3d476db0fe7a3c2227a54b36f904e27aca14f95759c39eb94 2024-12-08 18:00:00 UTC\n",
      "  0x233139629fe27474858b1f9669f54dad3a57d8d21dc4c129b1188271a0c51daf 2024-12-08 18:00:00 UTC\n",
      "  0x3a59784d74e1f1b88a36d37483eddf07054668e65a4424487cb479cc523a342b 2024-12-08 18:00:00 UTC\n",
      "  0xdbf84cb61acd00222a5b1192377b73785f8864f4066d9b2669e1f98b21af01d9 2024-12-08 18:00:00 UTC\n",
      "  0x38a4046f4eff4feea1fc0e506b2768081c0cbcba2dae53cba1a3c8781d3d0607 2024-12-08 18:00:00 UTC\n",
      "  0x07632cc8d0c6ae7ef9da2f34ba39471a38b8f123f4c54a5e46d7fbe806fbd3c3 2024-12-08 18:00:00 UTC\n",
      "  0xc53265a8fa3115889b09f4a2b6ea16e7c5b09ab803f4301b992ba7c1d017ba33 2024-12-08 20:30:00 UTC\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\nimro\\PolyQuant-features\")\n",
    "DB_PATH = BASE / \"sql\" / \"polymarket.db\"\n",
    "DATA_DIR = BASE / \"data\"\n",
    "\n",
    "def iso_z_to_epoch(s: str) -> int:\n",
    "    dt = datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=timezone.utc)\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "def ts_human(ts: int) -> str:\n",
    "    return datetime.fromtimestamp(int(ts), tz=timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "\n",
    "def load_market_end_ts(db_path: Path) -> dict:\n",
    "    con = sqlite3.connect(str(db_path))\n",
    "    try:\n",
    "        df = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT condition_id AS market_id, end_date\n",
    "            FROM markets\n",
    "            WHERE end_date IS NOT NULL\n",
    "            \"\"\",\n",
    "            con,\n",
    "        )\n",
    "    finally:\n",
    "        con.close()\n",
    "    df[\"market_id\"] = df[\"market_id\"].astype(str)\n",
    "    df[\"end_ts\"] = df[\"end_date\"].map(iso_z_to_epoch)\n",
    "    return dict(zip(df[\"market_id\"], df[\"end_ts\"]))\n",
    "\n",
    "market_end_ts = load_market_end_ts(DB_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15fcb5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample file: part-000002.parquet\n",
      "picked user_id: 0x9f47f1fcb1701bf9eaf31236ad39875e5d60af93\n",
      "rows for user in train: 259641\n",
      "\n",
      "Example: two consecutive trades (time-ordered for this user) where user_historical_pnl_before changes\n",
      "\n",
      "Trade A\n",
      "  trade_uid: b91fe3581abe2e82dd7961eceef0ea13aa6b7619\n",
      "  ts: 2023-06-08 17:00:26 UTC\n",
      "  market_id: 0x1d3e4f4b00c4d5ec6c11b469442a3e827b70d5be386d04941a960ba8ec380b56\n",
      "  market_end: 2023-06-09 00:00:00 UTC\n",
      "  price: 0.61000013000013 edge: -0.61000013000013\n",
      "  user_historical_pnl_before: 0.0\n",
      "\n",
      "Trade B\n",
      "  trade_uid: 671bf7e1f25b329bda475df0737c24247e06c81b\n",
      "  ts: 2023-06-09 10:31:40 UTC\n",
      "  market_id: 0x397395ad3f3cb595fa310507354787c40ff65efd385efbc4b6bf6632dfc1a3c6\n",
      "  market_end: 2023-09-01 00:00:00 UTC\n",
      "  price: 0.5399999988897191 edge: 0.46000000111028094\n",
      "  user_historical_pnl_before: -0.61000013000013\n",
      "\n",
      "Delta user_historical_pnl_before: -0.61000013000013\n",
      "\n",
      "Markets (that this user traded in train) with end_ts in (TradeA.ts, TradeB.ts]: 3\n",
      "  0x1d3e4f4b00c4d5ec6c11b469442a3e827b70d5be386d04941a960ba8ec380b56 2023-06-09 00:00:00 UTC\n",
      "  0xdf34a4b70b1dc462cddc0d298d7d44ecebe6ce1b5909054966fc591e6b34c062 2023-06-09 00:00:00 UTC\n",
      "  0xca06c276b89a1ff2afb02f8e7fa31e4ebd6588c4df03765cbe9dca25fab8eb23 2023-06-09 00:00:00 UTC\n"
     ]
    }
   ],
   "source": [
    "# ---- pick a user quickly from a random train parquet file ----\n",
    "train_files = sorted((DATA_DIR / \"train\").glob(\"*.parquet\"))\n",
    "p = random.choice(train_files)\n",
    "pf = pq.ParquetFile(str(p))\n",
    "u = pf.read_row_group(0, columns=[\"user_id\"]).column(0).to_pandas().astype(str)\n",
    "user_id = u.value_counts().index[0]\n",
    "print(\"sample file:\", p.name)\n",
    "print(\"picked user_id:\", user_id)\n",
    "\n",
    "# ---- load all rows for that user from TRAIN split only ----\n",
    "cols = [\"trade_uid\",\"user_id\",\"market_id\",\"timestamp\",\"price\",\"edge\",\"user_historical_pnl_before\"]\n",
    "dataset = ds.dataset(str(DATA_DIR / \"train\"), format=\"parquet\")\n",
    "\n",
    "table = dataset.to_table(\n",
    "    columns=cols,\n",
    "    filter=(ds.field(\"user_id\") == user_id),\n",
    ")\n",
    "df = table.to_pandas()\n",
    "df[\"market_id\"] = df[\"market_id\"].astype(str)\n",
    "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "print(\"rows for user in train:\", len(df))\n",
    "assert len(df) >= 2, \"Not enough rows for this user in train.\"\n",
    "\n",
    "# ---- find 2 consecutive trades where historical pnl feature changes ----\n",
    "pnl = pd.to_numeric(df[\"user_historical_pnl_before\"], errors=\"coerce\").fillna(0.0).astype(float).values\n",
    "d = np.abs(np.diff(pnl))\n",
    "idxs = np.where(d > 1e-6)[0]\n",
    "assert len(idxs) > 0, \"Did not find any consecutive trades with a pnl feature change for this user (in train).\"\n",
    "\n",
    "i = int(idxs[0])\n",
    "t1 = df.iloc[i]\n",
    "t2 = df.iloc[i+1]\n",
    "\n",
    "m1 = t1[\"market_id\"]\n",
    "m2 = t2[\"market_id\"]\n",
    "end1 = market_end_ts.get(m1, None)\n",
    "end2 = market_end_ts.get(m2, None)\n",
    "\n",
    "print(\"\\nExample: two consecutive trades (time-ordered for this user) where user_historical_pnl_before changes\\n\")\n",
    "\n",
    "print(\"Trade A\")\n",
    "print(\"  trade_uid:\", t1[\"trade_uid\"])\n",
    "print(\"  ts:\", ts_human(t1[\"timestamp\"]))\n",
    "print(\"  market_id:\", m1)\n",
    "print(\"  market_end:\", ts_human(end1) if end1 is not None else \"UNKNOWN\")\n",
    "print(\"  price:\", float(t1[\"price\"]), \"edge:\", float(t1[\"edge\"]))\n",
    "print(\"  user_historical_pnl_before:\", float(t1[\"user_historical_pnl_before\"]))\n",
    "\n",
    "print(\"\\nTrade B\")\n",
    "print(\"  trade_uid:\", t2[\"trade_uid\"])\n",
    "print(\"  ts:\", ts_human(t2[\"timestamp\"]))\n",
    "print(\"  market_id:\", m2)\n",
    "print(\"  market_end:\", ts_human(end2) if end2 is not None else \"UNKNOWN\")\n",
    "print(\"  price:\", float(t2[\"price\"]), \"edge:\", float(t2[\"edge\"]))\n",
    "print(\"  user_historical_pnl_before:\", float(t2[\"user_historical_pnl_before\"]))\n",
    "\n",
    "print(\"\\nDelta user_historical_pnl_before:\", float(t2[\"user_historical_pnl_before\"]) - float(t1[\"user_historical_pnl_before\"]))\n",
    "\n",
    "# Optional: which user-traded markets ended between those two trade timestamps?\n",
    "ts_a = int(t1[\"timestamp\"])\n",
    "ts_b = int(t2[\"timestamp\"])\n",
    "user_markets = df[\"market_id\"].unique()\n",
    "ended_between = []\n",
    "for mid in user_markets:\n",
    "    et = market_end_ts.get(mid, None)\n",
    "    if et is not None and ts_a < et <= ts_b:\n",
    "        ended_between.append((mid, et))\n",
    "\n",
    "ended_between.sort(key=lambda x: x[1])\n",
    "print(\"\\nMarkets (that this user traded in train) with end_ts in (TradeA.ts, TradeB.ts]:\", len(ended_between))\n",
    "for mid, et in ended_between[:10]:\n",
    "    print(\" \", mid, ts_human(et))\n",
    "if len(ended_between) > 10:\n",
    "    print(\"  ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1376ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_stable pairs: 255288\n",
      "suspicious pairs: 4264\n",
      "=== Expected stable examples (no eligible closure, pnl unchanged) ===\n",
      "Trade A: 2023-06-07 21:47:40 UTC market_end: 2023-09-01 00:00:00 UTC\n",
      "  market_id: 0x397395ad3f3cb595fa310507354787c40ff65efd385efbc4b6bf6632dfc1a3c6\n",
      "  pnl_before: 0.0\n",
      "Trade B: 2023-06-07 23:44:54 UTC market_end: 2023-07-30 00:00:00 UTC\n",
      "  market_id: 0x04bd2ccadea2c997bb946292f72a9dbbc86a937655e537ad824b0f3380dac750\n",
      "  pnl_before: 0.0\n",
      "Delta pnl_before: 0.0\n",
      "Eligible market closings in (A.ts, B.ts]: 0\n",
      "------------------------------------------------------------\n",
      "Trade A: 2023-06-07 23:44:54 UTC market_end: 2023-07-30 00:00:00 UTC\n",
      "  market_id: 0x04bd2ccadea2c997bb946292f72a9dbbc86a937655e537ad824b0f3380dac750\n",
      "  pnl_before: 0.0\n",
      "Trade B: 2023-06-08 06:58:51 UTC market_end: 2023-09-01 00:00:00 UTC\n",
      "  market_id: 0x397395ad3f3cb595fa310507354787c40ff65efd385efbc4b6bf6632dfc1a3c6\n",
      "  pnl_before: 0.0\n",
      "Delta pnl_before: 0.0\n",
      "Eligible market closings in (A.ts, B.ts]: 0\n",
      "------------------------------------------------------------\n",
      "Trade A: 2023-06-08 06:58:51 UTC market_end: 2023-09-01 00:00:00 UTC\n",
      "  market_id: 0x397395ad3f3cb595fa310507354787c40ff65efd385efbc4b6bf6632dfc1a3c6\n",
      "  pnl_before: 0.0\n",
      "Trade B: 2023-06-08 16:12:11 UTC market_end: 2023-06-13 00:00:00 UTC\n",
      "  market_id: 0x814f5f4ed96cc3666fc05923f42bb1fd7f9c436dfc923d06a624904bbe0b05f8\n",
      "  pnl_before: 0.0\n",
      "Delta pnl_before: 0.0\n",
      "Eligible market closings in (A.ts, B.ts]: 0\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Suspicious examples (no eligible closure, pnl changed) ===\n",
      "Trade A: 2023-06-09 21:03:36 UTC market_end: 2023-06-09 00:00:00 UTC\n",
      "  market_id: 0xdf34a4b70b1dc462cddc0d298d7d44ecebe6ce1b5909054966fc591e6b34c062\n",
      "  pnl_before: -0.61000013000013\n",
      "Trade B: 2023-06-09 21:03:50 UTC market_end: 2023-06-09 00:00:00 UTC\n",
      "  market_id: 0xdf34a4b70b1dc462cddc0d298d7d44ecebe6ce1b5909054966fc591e6b34c062\n",
      "  pnl_before: -0.99000013000013\n",
      "Delta pnl_before: -0.38\n",
      "Eligible market closings in (A.ts, B.ts]: 0\n",
      "------------------------------------------------------------\n",
      "Trade A: 2023-06-10 04:18:50 UTC market_end: 2023-06-09 00:00:00 UTC\n",
      "  market_id: 0xca06c276b89a1ff2afb02f8e7fa31e4ebd6588c4df03765cbe9dca25fab8eb23\n",
      "  pnl_before: -1.7500001300001298\n",
      "Trade B: 2023-06-10 06:35:44 UTC market_end: 2023-06-10 00:00:00 UTC\n",
      "  market_id: 0x5350cf22749cb59279c514dbdb70fc470f4fed16ff8635ec715f669906dfbc34\n",
      "  pnl_before: -1.9300001300001297\n",
      "Delta pnl_before: -0.17999999999999994\n",
      "Eligible market closings in (A.ts, B.ts]: 0\n",
      "------------------------------------------------------------\n",
      "Trade A: 2023-06-10 06:35:44 UTC market_end: 2023-06-10 00:00:00 UTC\n",
      "  market_id: 0x5350cf22749cb59279c514dbdb70fc470f4fed16ff8635ec715f669906dfbc34\n",
      "  pnl_before: -1.9300001300001297\n",
      "Trade B: 2023-06-10 08:10:20 UTC market_end: 2023-06-10 00:00:00 UTC\n",
      "  market_id: 0x5350cf22749cb59279c514dbdb70fc470f4fed16ff8635ec715f669906dfbc34\n",
      "  pnl_before: -2.12000013000013\n",
      "Delta pnl_before: -0.19000000000000017\n",
      "Eligible market closings in (A.ts, B.ts]: 0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from bisect import bisect_right, bisect_left\n",
    "\n",
    "DATA_DIR = Path(r\"C:\\Users\\nimro\\PolyQuant-features\\data\")\n",
    "\n",
    "def ts_human(ts: int) -> str:\n",
    "    return datetime.fromtimestamp(int(ts), tz=timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "\n",
    "# Load full user history across splits\n",
    "dataset = ds.dataset(str(DATA_DIR/\"train\"), format=\"parquet\")\n",
    "cols = [\"trade_uid\",\"user_id\",\"market_id\",\"timestamp\",\"price\",\"edge\",\"user_historical_pnl_before\"]\n",
    "table = dataset.to_table(columns=cols, filter=(ds.field(\"user_id\") == user_id))\n",
    "\n",
    "df_all = table.to_pandas()\n",
    "df_all[\"market_id\"] = df_all[\"market_id\"].astype(str)\n",
    "df_all[\"timestamp\"] = df_all[\"timestamp\"].astype(np.int64)\n",
    "df_all[\"user_historical_pnl_before\"] = pd.to_numeric(df_all[\"user_historical_pnl_before\"], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "df_all = df_all.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# first trade time per market (for eligibility)\n",
    "first_ts = df_all.groupby(\"market_id\")[\"timestamp\"].min().to_dict()\n",
    "\n",
    "# closures list: (end_ts, market_id, first_trade_ts)\n",
    "closures = []\n",
    "for mid, ft in first_ts.items():\n",
    "    et = market_end_ts.get(mid)\n",
    "    if et is not None:\n",
    "        closures.append((int(et), mid, int(ft)))\n",
    "closures.sort()  # by end_ts\n",
    "end_ts_sorted = [x[0] for x in closures]\n",
    "\n",
    "len(df_all), len(closures)\n",
    "\n",
    "def eligible_closures_between(t0: int, t1: int):\n",
    "    # markets with end_ts in (t0, t1] and first_trade_ts <= t0\n",
    "    lo = bisect_right(end_ts_sorted, t0)\n",
    "    hi = bisect_right(end_ts_sorted, t1)\n",
    "    out = []\n",
    "    for k in range(lo, hi):\n",
    "        et, mid, ft = closures[k]\n",
    "        if ft <= t0:\n",
    "            out.append((mid, et, ft))\n",
    "    return out\n",
    "\n",
    "pnl = df_all[\"user_historical_pnl_before\"].values\n",
    "ts  = df_all[\"timestamp\"].values\n",
    "\n",
    "eps = 1e-9\n",
    "expected_stable = []\n",
    "suspicious = []\n",
    "\n",
    "for i in range(len(df_all) - 1):\n",
    "    t0, t1 = int(ts[i]), int(ts[i+1])\n",
    "    d = float(pnl[i+1] - pnl[i])\n",
    "    ends = eligible_closures_between(t0, t1)\n",
    "\n",
    "    if len(ends) == 0:\n",
    "        if abs(d) <= eps:\n",
    "            expected_stable.append(i)\n",
    "        else:\n",
    "            suspicious.append(i)\n",
    "\n",
    "print(\"expected_stable pairs:\", len(expected_stable))\n",
    "print(\"suspicious pairs:\", len(suspicious))\n",
    "\n",
    "expected_stable[:5], suspicious[:5]\n",
    "\n",
    "def show_pair(i: int):\n",
    "    a = df_all.iloc[i]\n",
    "    b = df_all.iloc[i+1]\n",
    "    t0, t1 = int(a[\"timestamp\"]), int(b[\"timestamp\"])\n",
    "    ends = eligible_closures_between(t0, t1)\n",
    "    d = float(b[\"user_historical_pnl_before\"] - a[\"user_historical_pnl_before\"])\n",
    "\n",
    "    def mend(mid):\n",
    "        et = market_end_ts.get(mid)\n",
    "        return ts_human(et) if et is not None else \"UNKNOWN\"\n",
    "\n",
    "    print(\"Trade A:\", ts_human(t0), \"market_end:\", mend(a[\"market_id\"]))\n",
    "    print(\"  market_id:\", a[\"market_id\"])\n",
    "    print(\"  pnl_before:\", float(a[\"user_historical_pnl_before\"]))\n",
    "    print(\"Trade B:\", ts_human(t1), \"market_end:\", mend(b[\"market_id\"]))\n",
    "    print(\"  market_id:\", b[\"market_id\"])\n",
    "    print(\"  pnl_before:\", float(b[\"user_historical_pnl_before\"]))\n",
    "    print(\"Delta pnl_before:\", d)\n",
    "\n",
    "    print(\"Eligible market closings in (A.ts, B.ts]:\", len(ends))\n",
    "    for mid, et, ft in ends[:10]:\n",
    "        print(\" \", mid, \"end:\", ts_human(et), \"first_trade:\", ts_human(ft))\n",
    "    if len(ends) > 10:\n",
    "        print(\"  ...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"=== Expected stable examples (no eligible closure, pnl unchanged) ===\")\n",
    "for i in expected_stable[:3]:\n",
    "    show_pair(i)\n",
    "\n",
    "print(\"\\n=== Suspicious examples (no eligible closure, pnl changed) ===\")\n",
    "for i in suspicious[:3]:\n",
    "    show_pair(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf2b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
